Відповіді на запитання:

1) Подумайте, чому при додаванні однієї проміжної дії nuek_processed.collect(), отримано аж на 3 Job більше?


5 джобів у частині 1 - тому, що було лише виконання трансформацій, що не викликають додаткових обчислень до виклику action. 
Після додавання в Частині 2 ще одного collect(), кожен з них ініціював додаткові етапи виконання,
збільшивши кількість джобів до 8.



2) Подумайте, чому при використанні cache() ми зменшили кількість Job?


При використанні cache() реалізувалась оптимізація обчислення, оскільки PySpark не доводиться перераховувати однакові етапи кожного разу.
Це зменшило кількість створюваних джобів, бо вони виконуються одноразово, наступні операції працюють з кешованими даними.

